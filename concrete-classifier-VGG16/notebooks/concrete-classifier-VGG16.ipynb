{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necassary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29958 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    '../input/concrete_data/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=100,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10042 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = data_generator.flow_from_directory(\n",
    "    '../input/concrete_data/valid',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=100,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 17s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model.add(VGG16(include_top=False, pooling='avg', weights='imagenet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1d04ebe32d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d04e3952d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d0503d8910>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1d006630710>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d050ae1090>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d05044aa10>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1d050ae0910>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d050b110d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d05002cf10>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d050b2eb10>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1d050b2ed50>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d050b17310>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d050b16d50>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d050b07610>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1d050449110>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d050afa590>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d050b15d90>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1d05002fa90>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1d050b074d0>,\n",
       " <keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x1d05042ddd0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers # VGG16 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 512)               14714688  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "300/300 [==============================] - 1950s 6s/step - loss: 0.0920 - accuracy: 0.9677 - val_loss: 0.0253 - val_accuracy: 0.9941\n",
      "Epoch 2/2\n",
      "300/300 [==============================] - 1809s 6s/step - loss: 0.0188 - accuracy: 0.9958 - val_loss: 0.0150 - val_accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d050b04d50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=2, validation_data=valid_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"item43\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/classifier_vgg16_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
